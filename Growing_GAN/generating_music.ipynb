{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ba93a7",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb272a8",
   "metadata": {},
   "source": [
    "This notebook uses an already trained generator to generate audio data. The first possibility is to generate a single random song and plot the waveform. The second possibility is to change the values of the latent vector individually and observe the influence on the generated song."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76922d85",
   "metadata": {},
   "source": [
    "# Imports and Gloabl Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990db230",
   "metadata": {},
   "source": [
    "* The library numpy is used to create and load the training data and to execute mathmatical operations. \n",
    "* The library librosa is used to plot a wavefrom\n",
    "* The library tensorflow is used create, save and load models and layers\n",
    "* The library soundfile is used to convert wavefrom data to a WAV format\n",
    "* The library pyaudio is used to play the songs in the brackground\n",
    "* The library wave is used to provide the waveform data to pyaudio\n",
    "* The library time is used to delay execution of code\n",
    "* The library ipywidgets is used to build interactive python function to manipulate the audio data\n",
    "* The library IPython is used to show the interactive sliders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae239a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:08:29.212858Z",
     "start_time": "2021-11-26T13:08:25.526015Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "import soundfile as sf\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact,interactive,fixed,interact_manual\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e7c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:08:29.258526Z",
     "start_time": "2021-11-26T13:08:29.244112Z"
    }
   },
   "outputs": [],
   "source": [
    "MONITORING_DIR = \"./Monitoring\" # where the generator is saved to generate audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22f9e4",
   "metadata": {},
   "source": [
    "# Custom Layers\n",
    "Same layers as defined in the notebook \"model.ipynb\". They are needed to load the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e8e3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:08:29.305530Z",
     "start_time": "2021-11-26T13:08:29.290823Z"
    }
   },
   "outputs": [],
   "source": [
    "class WeightedSum(keras.layers.Add):\n",
    "    '''\n",
    "    inherits from keras Add layer\n",
    "    takes to inputs multiplies them by a factor and adds them up\n",
    "    outputs the weighted sum \n",
    "    '''\n",
    "    # init with default value\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)   # initializes the parent class constructor\n",
    "        self.alpha = keras.backend.variable(alpha, name='ws_alpha') # initializes the class variales alpha\n",
    "\n",
    "    # output a weighted sum of inputs\n",
    "    def _merge_function(self, inputs):\n",
    "        # only supports a weighted sum of two inputs\n",
    "        assert (len(inputs) == 2) # make sure it is only two inputs\n",
    "        # ((1-a) * input1) + (a * input2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1]) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad12bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:08:29.352603Z",
     "start_time": "2021-11-26T13:08:29.338591Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class PixelNormalization(keras.layers.Layer):\n",
    "    '''\n",
    "    inherits from keras layer\n",
    "    scales the feature vector for every position to unit length\n",
    "    '''\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNormalization, self).__init__(**kwargs) # initializes the parent class constructor\n",
    "\n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        values = inputs**2.0 # calculate square signal values     \n",
    "        mean_values = keras.backend.mean(values, axis=-1, keepdims=True) # calculate the mean signal values      \n",
    "        mean_values += 1.0e-8 # ensure the mean is not zero\n",
    "        l2 = keras.backend.sqrt(mean_values) # calculate the sqrt of the mean squared value (L2 norm)\n",
    "        normalized = inputs / l2 # normalize values by the l2 norm\n",
    "        return normalized\n",
    "\n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f1327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:08:29.398709Z",
     "start_time": "2021-11-26T13:08:29.385379Z"
    }
   },
   "outputs": [],
   "source": [
    "class Conv1DEQ_load(keras.layers.Conv1D):\n",
    "    \"\"\"\n",
    "    inherits conv1d from keras layers \n",
    "    extends this by applying scaling of the weights with He's per-layer constant \n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs) # initialize parent constructor without weight initialization\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        # The number of inputs\n",
    "        n = np.product([self.kernel_size[0],input_shape[-1]])\n",
    "        # He initialisation constant\n",
    "        self.c = np.sqrt(2/n)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        outputs = tf.nn.conv1d(\n",
    "            inputs,\n",
    "            self.kernel*self.c, # scale kernel\n",
    "            stride=self.strides,\n",
    "            padding=\"SAME\")\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = tf.nn.bias_add(\n",
    "                outputs,\n",
    "                self.bias)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69722ddf",
   "metadata": {},
   "source": [
    "# Generate Data\n",
    "\n",
    "When the generator is first used to generate a song, a graph of the network is build and saved to memory. So the first time when a song is generated the execution time is large. For all further generation steps one song can be produced in under a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81706fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:08:29.445912Z",
     "start_time": "2021-11-26T13:08:29.431841Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743bd329",
   "metadata": {},
   "source": [
    "## Utils\n",
    "Some funcitons needed to build the interactive interface. \\\n",
    "The \"play_audio\" funciton is taken from: https://people.csail.mit.edu/hubert/pyaudio/docs/#pyaudio.get_format_from_width \\\n",
    "The widgets are inspired by: https://ipywidgets.readthedocs.io/en/stable/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11ee43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:11:48.105901Z",
     "start_time": "2021-11-26T13:11:48.100915Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_waveform(new_song):\n",
    "    '''\n",
    "    plots the waveform\n",
    "    new_song: waveform data as numpy array\n",
    "    '''\n",
    "    librosa.display.waveplot(new_song,alpha = 0.5,sr = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0055fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:08:29.741189Z",
     "start_time": "2021-11-26T13:08:29.732214Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def play_audio(click):\n",
    "    '''\n",
    "    Plays the audio wavefrom generated by the user through the interactive sliders\n",
    "    The function is executed when button b is pressed\n",
    "    click: Button object\n",
    "    '''\n",
    "    def callback(in_data, frame_count, time_info, status):\n",
    "        '''\n",
    "        is called for every frame of the audio data and return the audio that is to be played\n",
    "        '''\n",
    "        data = wf.readframes(frame_count) # provides data frame\n",
    "        return (data, pyaudio.paContinue) \n",
    "    try:\n",
    "        p = pyaudio.PyAudio() # creates pyaudio object\n",
    "        wf = wave.open(\"./generated_song.wav\", 'rb') # opens the song genrated by the user\n",
    "        stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                        channels=wf.getnchannels(),\n",
    "                        rate=wf.getframerate(),\n",
    "                        output=True,\n",
    "                        stream_callback=callback) # defines the stream and calls funtion callback\n",
    "\n",
    "        stream.start_stream() # starts the audio stream\n",
    "\n",
    "        while stream.is_active(): # wait for stream to finish \n",
    "            time.sleep(0.1)\n",
    "        stream.stop_stream() # stop stream \n",
    "        stream.close() # close stream object\n",
    "        wf.close() # close audio object\n",
    "        p.terminate() # terminate pyaudio object\n",
    "    except: print(\"Please create a wavefrom first by changing slider values!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717b242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:08:30.655340Z",
     "start_time": "2021-11-26T13:08:30.643372Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_plot(update):\n",
    "    ''' \n",
    "    Is executed for every value change of the silders\n",
    "    '''\n",
    "    ax.clear() # clears plot\n",
    "    new_latent_rep = [] # instantiate latent vector as a list\n",
    "    for i in sliders.values(): # loop through all slider values\n",
    "        new_latent_rep.append(i.value) # append slider value to latent vector\n",
    "    \n",
    "    new_latent_rep = np.array([new_latent_rep]) # convert to numpy array\n",
    "        \n",
    "    new_song = generator(new_latent_rep) # generate audio data\n",
    "    new_song = new_song.numpy().reshape((number_of_samples,)) # reshape audio data\n",
    "    sf.write(\"./generated_song.wav\", new_song, sr) # save audio as wav\n",
    "    target=plot_waveform(new_song) # plot waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb881ee9",
   "metadata": {},
   "source": [
    "## load the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc91ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:08:36.507337Z",
     "start_time": "2021-11-26T13:08:31.194769Z"
    }
   },
   "outputs": [],
   "source": [
    "### change values\n",
    "iteration = 7 # iteration from which to load the generator\n",
    "latest_epoch = 4 # epoch from which to load the generator\n",
    "\n",
    "### calculatation\n",
    "sr = int(86.1328125*2**iteration)\n",
    "number_of_samples= 1024*2**iteration  # calculates number of samples needed for the audio file\n",
    "\n",
    "\n",
    "# load a generator model \n",
    "generator = load_model(f'./{MONITORING_DIR}/iteration_{iteration}_generator_epoch_{latest_epoch}.h5', custom_objects={\n",
    "                                                                                'PixelNormalization': PixelNormalization,\n",
    "                                                                                'WeightedSum': WeightedSum,\n",
    "                                                                                'Conv1DEQ':Conv1DEQ_load})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb031d8",
   "metadata": {},
   "source": [
    "## generate a single random song\n",
    "In this part a single random song is generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a297588d",
   "metadata": {},
   "source": [
    "### generate the waveform data from a latent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830a8d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:09:35.377498Z",
     "start_time": "2021-11-26T13:08:36.538683Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_points = tf.random.uniform(shape=(1,latent_dim),minval=-1, maxval=1) # generate latent vector\n",
    "X = generator.predict(latent_points) # predict waveform with the generator\n",
    "sound_file = X[0].reshape((1024*2**iteration,)) # change the shape to standard wavefrom data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81eed4",
   "metadata": {},
   "source": [
    "### plot the waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240eb80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:10:10.503411Z",
     "start_time": "2021-11-26T13:10:10.142177Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1,figsize=(10,5))\n",
    "plot_waveform(sound_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd0c5e",
   "metadata": {},
   "source": [
    "### generate the WAV soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b2a32",
   "metadata": {},
   "source": [
    "The path variables can be changed to save the song with a distinct name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8397d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:51:45.922982Z",
     "start_time": "2021-11-26T10:51:45.914007Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"./random_song.wav\"\n",
    "sf.write(path, sound_file, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ffecd7",
   "metadata": {},
   "source": [
    "## Exploring the latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c23cfd",
   "metadata": {},
   "source": [
    "The user is able to manipulate all variables of the latent vector that are passed to the generator. The waveform is plotted and the audio can be played."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4ffcb8",
   "metadata": {},
   "source": [
    "Every slider changes one value of the latent vector. The resulting waveform is directly displayed in a new window. When the button \"Play song\" is pressed the shown waveform is played in the background. When the song is done playing the waveform can be changed again. At least on value has to be initally changed to display a waveform and to play a song.\n",
    "\n",
    "With the variable \"initialsize_random\" the intial slider values can be set to a random value instead of all being zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f89f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T09:57:45.766299Z",
     "start_time": "2021-11-24T09:57:45.754407Z"
    }
   },
   "outputs": [],
   "source": [
    "initialsize_random = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae3c99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T09:57:48.328461Z",
     "start_time": "2021-11-24T09:57:47.025942Z"
    }
   },
   "outputs": [],
   "source": [
    "# if set to true all slider values are initialized randomly if false then all are set to zero\n",
    "if initialsize_random:\n",
    "    values = tf.random.uniform(shape=(1,latent_dim),minval=-1, maxval=1)[0].numpy()\n",
    "else: values = tf.zeros(latent_dim).numpy()\n",
    "    \n",
    "# makes the plot appear in a new window\n",
    "%matplotlib qt \n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(15,8)) # set plot size\n",
    "plt.suptitle(\"New Song\") # plot title\n",
    "\n",
    "sliders = {} # instaiate dict for the sliders\n",
    "out = widgets.Output() # widgets output object mandatory\n",
    "\n",
    "for k in range(1,latent_dim+1): # create key value pair for the slider for every position of the latent vector\n",
    "    variable = f\"variable_{k}\" # key name\n",
    "    value = widgets.FloatSlider(min=-1,\n",
    "                        max = 1,\n",
    "                        value = values[k-1],\n",
    "                        step=0.02,\n",
    "                        description=f'{k}:') # dict value\n",
    "    sliders[variable] = value # add key value pair to dict\n",
    "\n",
    "for slider in sliders.values():\n",
    "    slider.observe(update_plot, names = \"value\") # observe all sliders and call function update_plot when there change\n",
    "\n",
    "controls = {} # list for the slider objects than should be displayed\n",
    "for i in range(0,latent_dim+1,4): # creating a horizontal box which 4 sliders each\n",
    "    name = f\"c{i}\"\n",
    "    value = widgets.HBox(list(sliders.values())[i:i+4])\n",
    "\n",
    "    controls[name]=value\n",
    "    \n",
    "        \n",
    "# button design\n",
    "b = widgets.Button(\n",
    "    description='Play song',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='You need to change some slider values first',\n",
    "    icon='' \n",
    ")    \n",
    "\n",
    "b2 = widgets.Button(\n",
    "    description='Set random values',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Set the sliders to random values',\n",
    "    icon='' \n",
    ")   \n",
    "    \n",
    "display(b,widgets.VBox([controls[f\"c{i}\"] for i in range(0,latent_dim+1,4)]+[out])) # display sliders\n",
    "b.on_click(play_audio) # when button b is pressed play audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeda629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.54499999999999,
   "position": {
    "height": "40px",
    "left": "1126.36px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
